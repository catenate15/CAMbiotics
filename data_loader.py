import os
import torch
import pytorch_lightning as pl
from torch.utils.data import DataLoader, Dataset
from data_preprocessing import SMILESDataset # Assuming data_preprocessing.py is in the same directory or the path is set correctly
import pandas as pd

# Define a custom Dataset
class SMILESDataset(Dataset):
    def __init__(self, csv_file):
        # Check if file exists before attempting to load
        if not os.path.isfile(csv_file):
            print(f"Error: The file {csv_file} does not exist. Please ensure it is generated by data_preprocessing.py module.")
            raise FileNotFoundError(f"The file {csv_file} does not exist.")
        
        self.data_frame = pd.read_csv(csv_file)
        self.smiles = list(self.data_frame['Encoded_SMILES'])
        self.activities = list(self.data_frame['Activity'])
        print(f"Dataset loaded with {len(self.smiles)} entries from {csv_file}")

    def __len__(self):
        return len(self.smiles)

    def __getitem__(self, idx):
        # Assuming the SMILES are already encoded and just need to be converted to tensors
        smiles_tensor = torch.tensor(self.smiles[idx], dtype=torch.float)
        activity_tensor = torch.tensor(self.activities[idx], dtype=torch.float)
        return smiles_tensor, activity_tensor

# Define the DataModule
class SMILESDataModule(pl.LightningDataModule):
    def __init__(self, base_file_path, batch_size=32):
        super().__init__()
        self.base_file_path = base_file_path
        self.batch_size = batch_size


    def setup(self, stage=None): # stage can be used to differentiate between training, validation, and test None by default means for all three, fit means for training, validate means for validation, test means for test
        try:
            self.train_dataset = SMILESDataset(f'{self.base_file_path}_Train.csv')
            self.val_dataset = SMILESDataset(f'{self.base_file_path}_Valid.csv')
            self.test_dataset = SMILESDataset(f'{self.base_file_path}_Test.csv')
        except FileNotFoundError as e:
            print(e)
            print("Please ensure the training, validation, and test CSV files are present as expected.")


    def train_dataloader(self):
        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)

    def val_dataloader(self):
        return DataLoader(self.val_dataset, batch_size=self.batch_size)

    def test_dataloader(self):
        return DataLoader(self.test_dataset, batch_size=self.batch_size)
